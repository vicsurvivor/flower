{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22293679",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 08:59:27.754896: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-21 08:59:27.781147: I tensorflow/core/platform/cpu_feature_guard.cc:211] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2L, preprocess_input\n",
    "from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2S,EfficientNetV2M,EfficientNetV2L\n",
    "from tensorflow.keras.applications.convnext import ConvNeXtTiny,ConvNeXtSmall,ConvNeXtBase\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.data import AUTOTUNE\n",
    "from sklearn.model_selection import KFold\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7be7aa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_paths_and_labels(directory):\n",
    "    file_paths = []\n",
    "    labels = []\n",
    "    class_names = sorted(os.listdir(directory))\n",
    "    class_to_index = {class_name: idx for idx, class_name in enumerate(class_names)}\n",
    "\n",
    "    for class_name in class_names:\n",
    "        class_path = os.path.join(directory, class_name)\n",
    "        for fname in os.listdir(class_path):\n",
    "            fpath = os.path.join(class_path, fname)\n",
    "            if os.path.isfile(fpath):\n",
    "                file_paths.append(fpath)\n",
    "                labels.append(class_to_index[class_name])\n",
    "\n",
    "    return np.array(file_paths), np.array(labels), class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a44560d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 08:59:31.339071: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-21 08:59:31.358039: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-21 08:59:31.358065: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "# 方法1：限制GPU記憶體成長\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "# 設定參數\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 500\n",
    "\n",
    "# 資料路徑\n",
    "TRAINING_DIR = \"datasets/flower_photos/Training\"\n",
    "TEST_DIR = \"datasets/flower_photos/Inference\"\n",
    "\n",
    "KFOLD = 5  # 你可以改成 10-fold 等\n",
    "\n",
    "\n",
    "\n",
    "file_paths, labels, class_names = get_file_paths_and_labels(TRAINING_DIR)\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e82fa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(image, label):\n",
    "    # image = tf.image.random_flip_left_right(image)\n",
    "    # image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "    # image = tf.image.random_contrast(image, 0.8, 1.2)\n",
    "    # image = tf.image.random_hue(image, max_delta=0.2)\n",
    "    # image = tf.image.random_saturation(image, 0.8, 1.2)\n",
    "    # image = preprocess_input(image)\n",
    "    label = tf.one_hot(label, num_classes)\n",
    "    return image, label\n",
    "\n",
    "def preprocess(image, label):\n",
    "    # image = preprocess_input(image)\n",
    "    label = tf.one_hot(label, num_classes)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5b044cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(Model):\n",
    "    base_model = Model(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3826d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_summary(Model_list):\n",
    "#     for Model in Model_list:\n",
    "#         m = create_model(Model)\n",
    "#         print(m.summary())\n",
    "#         del m\n",
    "# get_summary([EfficientNetV2S,EfficientNetV2M,EfficientNetV2L,ConvNeXtTiny,ConvNeXtSmall,ConvNeXtBase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a73ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_model():\n",
    "#     base_model = ConvNeXtBase(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "#     base_model.trainable = False\n",
    "\n",
    "#     model = Sequential([\n",
    "#         base_model,\n",
    "#         layers.GlobalAveragePooling2D(),\n",
    "#         layers.Dense(256, activation='relu'),\n",
    "#         layers.Dropout(0.5),\n",
    "#         layers.Dense(num_classes, activation='softmax')\n",
    "#     ])\n",
    "\n",
    "#     model.compile(\n",
    "#         optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "#         loss='categorical_crossentropy',\n",
    "#         metrics=['accuracy']\n",
    "#     )\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7acb29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, model_name):\n",
    "    # 擷取訓練和驗證的損失與準確率\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    train_accuracy = history.history['accuracy']\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "    epochs_range = range(1, len(train_loss) + 1)\n",
    "\n",
    "    # 創建畫布為 1x2 的子圖\n",
    "    plt.figure(figsize=(12, 5))  \n",
    "\n",
    "    # 作圖損失\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, train_loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.title(f'{model_name} Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # 作圖準確率\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, train_accuracy, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_accuracy, label='Validation Accuracy')\n",
    "    plt.title(f'{model_name} Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # 顯示圖片\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{model_name} Loss and Accuracy\")\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def plot_confusion_matrix(y_true, y_pred, labels=None, title='Confusion Matrix'):\n",
    "    \"\"\"\n",
    "    繪製混淆矩陣的函數。\n",
    "    \n",
    "    參數:\n",
    "    y_true: 真實標籤列表或數組。\n",
    "    y_pred: 預測標籤列表或數組。\n",
    "    labels: 標籤的名稱列表，用於標記矩陣的軸。\n",
    "    title: 圖表的標題。\n",
    "    \"\"\"\n",
    "    # 計算混淆矩陣\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    # 創建一個熱圖，顯示混淆矩陣\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title(title)\n",
    "    plt.savefig(f\"Inference confusion metrix\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm_normalized, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    \n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title(f'{title} normalized')\n",
    "    plt.savefig(f\"Inference confusion metrix normalized\")\n",
    "    plt.show()\n",
    "    \n",
    "def plot_misclassified_with_probabilities(test_dataset, model_name ,y_true, y_pred, y_probs, class_names, num_images_to_plot=5):\n",
    "    \"\"\"\n",
    "    畫出預測錯誤的圖片。\n",
    "    \n",
    "    參數:\n",
    "    - test_dataset: 用於測試的tf.data.Dataset物件。\n",
    "    - y_true: 真實標籤的數組或列表。\n",
    "    - y_pred: 預測標籤的數組或列表。\n",
    "    - class_names: 分類標籤名稱的列表。\n",
    "    - num_images_to_plot: 要顯示的錯誤圖片的數量。\n",
    "    \"\"\"\n",
    "    # 找出預測錯誤的 index\n",
    "      # 找出預測錯誤的 index\n",
    "    incorrect_indices = np.where(np.array(y_true) != np.array(y_pred))[0]\n",
    "\n",
    "    if len(incorrect_indices) == 0:\n",
    "        print(\"所有圖片均正確分類！\")\n",
    "        return\n",
    "    \n",
    "    num_plots = min(num_images_to_plot, len(incorrect_indices))\n",
    "    print(f\"最少繪製'{num_plots}'張圖片\")\n",
    "    # 計算行列數目\n",
    "    cols = 5\n",
    "    rows = (num_plots + cols - 1) // cols  # 向上取整\n",
    "\n",
    "    plt.figure(figsize=(15, 5 * rows))\n",
    "\n",
    "    count = 0\n",
    "    global_index = 0\n",
    "    for images, _ in test_dataset:\n",
    "        for i in range(len(images)): #batch?32\n",
    "            if count >= num_plots:\n",
    "                break\n",
    "            if global_index in incorrect_indices:\n",
    "                # 獲取該圖片真實標籤與預測信息\n",
    "                true_label_index = class_names.get(y_true[global_index]) #0123\n",
    "                predicted_label_index = class_names.get(y_pred[global_index]) #0123\n",
    "                true_label_prob = y_probs[global_index][true_label_index]\n",
    "                predicted_label_prob = y_probs[global_index][predicted_label_index]\n",
    "                \n",
    "                ax = plt.subplot(rows, cols, count + 1)\n",
    "                plt.imshow(images[i].numpy().astype(\"int32\"))  # 確保圖片是可視化格式\n",
    "                plt.title(f\"True: {y_true[global_index]} ({true_label_prob:.2f})\\n\"\n",
    "                          f\"Pred: {y_pred[global_index]} ({predicted_label_prob:.2f})\")\n",
    "                plt.axis(\"off\")\n",
    "                count += 1\n",
    "            global_index += 1\n",
    "\n",
    "        if count >= num_plots:\n",
    "            break\n",
    "    plt.title(f\"{model_name} wrong predicted images\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{model_name} wrong predicted images\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f964fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(file_paths)):\n",
    "    print(f\"\\n========== Fold {fold + 1} ==========\")\n",
    "\n",
    "    train_paths, val_paths = file_paths[train_idx], file_paths[val_idx]\n",
    "    train_labels, val_labels = labels[train_idx], labels[val_idx]\n",
    "\n",
    "    # 建立 Dataset\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\n",
    "    val_ds = tf.data.Dataset.from_tensor_slices((val_paths, val_labels))\n",
    "\n",
    "    # 讀圖片\n",
    "    def load_and_preprocess_image(path, label):\n",
    "        image = tf.io.read_file(path)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH])\n",
    "        return image, label\n",
    "\n",
    "    train_ds = train_ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE).map(augment).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    val_ds = val_ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE).map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    # 建立 model & callbacks\n",
    "    model = create_model(ConvNeXtSmall)\n",
    "\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6),\n",
    "        tf.keras.callbacks.ModelCheckpoint(f'ConvNeXtSmall_best_model_fold{fold + 1}.h5', monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "    ]\n",
    "\n",
    "    history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, callbacks=callbacks)\n",
    "    plot_training_history(history,\"ConvNeXtSmall\")\n",
    "    test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    TEST_DIR,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    shuffle=False\n",
    "    )\n",
    "    test_dataset = test_dataset.map(preprocess)\n",
    "    true_labels = []\n",
    "    for _, label in test_dataset:\n",
    "        batch_labels = label.numpy()\n",
    "        class_indices = np.argmax(batch_labels, axis=1)\n",
    "        true_labels.extend(class_indices)\n",
    "\n",
    "    # 最後一個 fold 測試\n",
    "    loss, acc = model.evaluate(test_dataset)\n",
    "    print(f\"Inference Test Accuracy (Last Fold): {acc:.4f}\")\n",
    "    with open(\"test_inference.txt\",\"+a\",encoding=\"utf-8\") as file:\n",
    "        file.write(f\"Fold {fold+1} Inference metric loss:{loss}, acc:{acc}\\n\")\n",
    "    evaluate_result = model.evaluate(test_dataset)\n",
    "    predict_result = model.predict(test_dataset)\n",
    "    predict_classes = np.argmax(predict_result,axis=1)\n",
    "    reverse_name = {k:v for k,v in enumerate(class_names)}\n",
    "    y_true = [reverse_name.get(i) for i in true_labels]\n",
    "    y_pred = [reverse_name.get(i) for i in predict_classes]\n",
    "    name_to_int = {v:k for k,v in enumerate(class_names)}\n",
    "    plot_confusion_matrix(y_true=y_true,y_pred=y_pred,labels=class_names)\n",
    "    plot_misclassified_with_probabilities(test_dataset, model_name=\"ConvNeXtSmall\", y_true=y_true, y_pred=y_pred, y_probs=predict_result, class_names=name_to_int, num_images_to_plot=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d6f7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"best_model_fold1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984a2b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_result =model.evaluate(test_dataset)\n",
    "predict_result =model.predict(test_dataset)\n",
    "predict_classes = np.argmax(predict_result,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f908f30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_name = {k:v for k,v in enumerate(class_names)}\n",
    "y_true = [reverse_name.get(i) for i in true_labels]\n",
    "y_pred = [reverse_name.get(i) for i in predict_classes]\n",
    "name_to_int = {v:k for k,v in enumerate(class_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aea1373",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_true=y_true,y_pred=y_pred,labels=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cbe168",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6561ea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_misclassified_with_probabilities(test_dataset, y_true=y_true, y_pred=y_pred, y_probs=predict_result, class_names=name_to_int, num_images_to_plot=61)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfc32d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba29e20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
