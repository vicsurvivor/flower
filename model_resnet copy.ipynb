{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22293679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2L, preprocess_input\n",
    "from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2S,EfficientNetV2M,EfficientNetV2L\n",
    "from tensorflow.keras.applications.convnext import ConvNeXtTiny,ConvNeXtSmall,ConvNeXtBase\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.data import AUTOTUNE\n",
    "from sklearn.model_selection import KFold\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be7aa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_paths_and_labels(directory):\n",
    "    file_paths = []\n",
    "    labels = []\n",
    "    class_names = sorted(os.listdir(directory))\n",
    "    class_to_index = {class_name: idx for idx, class_name in enumerate(class_names)}\n",
    "\n",
    "    for class_name in class_names:\n",
    "        class_path = os.path.join(directory, class_name)\n",
    "        for fname in os.listdir(class_path):\n",
    "            fpath = os.path.join(class_path, fname)\n",
    "            if os.path.isfile(fpath):\n",
    "                file_paths.append(fpath)\n",
    "                labels.append(class_to_index[class_name])\n",
    "\n",
    "    return np.array(file_paths), np.array(labels), class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44560d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 方法1：限制GPU記憶體成長\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "# 設定參數\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 500\n",
    "\n",
    "# 資料路徑\n",
    "TRAINING_DIR = \"datasets/flower_photos/Training\"\n",
    "TEST_DIR = \"datasets/flower_photos/Inference\"\n",
    "\n",
    "KFOLD = 5  # 你可以改成 10-fold 等\n",
    "\n",
    "\n",
    "\n",
    "file_paths, labels, class_names = get_file_paths_and_labels(TRAINING_DIR)\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e82fa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(image, label):\n",
    "    # image = tf.image.random_flip_left_right(image)\n",
    "    # image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "    # image = tf.image.random_contrast(image, 0.8, 1.2)\n",
    "    # image = tf.image.random_hue(image, max_delta=0.2)\n",
    "    # image = tf.image.random_saturation(image, 0.8, 1.2)\n",
    "    # image = preprocess_input(image)\n",
    "    label = tf.one_hot(label, num_classes)\n",
    "    return image, label\n",
    "\n",
    "def preprocess(image, label):\n",
    "    # image = preprocess_input(image)\n",
    "    label = tf.one_hot(label, num_classes)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b044cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(Model):\n",
    "    base_model = Model(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3826d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_summary(Model_list):\n",
    "#     for Model in Model_list:\n",
    "#         m = create_model(Model)\n",
    "#         print(m.summary())\n",
    "#         del m\n",
    "# get_summary([EfficientNetV2S,EfficientNetV2M,EfficientNetV2L,ConvNeXtTiny,ConvNeXtSmall,ConvNeXtBase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a73ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_model():\n",
    "#     base_model = ConvNeXtBase(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "#     base_model.trainable = False\n",
    "\n",
    "#     model = Sequential([\n",
    "#         base_model,\n",
    "#         layers.GlobalAveragePooling2D(),\n",
    "#         layers.Dense(256, activation='relu'),\n",
    "#         layers.Dropout(0.5),\n",
    "#         layers.Dense(num_classes, activation='softmax')\n",
    "#     ])\n",
    "\n",
    "#     model.compile(\n",
    "#         optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "#         loss='categorical_crossentropy',\n",
    "#         metrics=['accuracy']\n",
    "#     )\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7acb29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, model_name):\n",
    "    # 擷取訓練和驗證的損失與準確率\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    train_accuracy = history.history['accuracy']\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "    epochs_range = range(1, len(train_loss) + 1)\n",
    "\n",
    "    # 創建畫布為 1x2 的子圖\n",
    "    plt.figure(figsize=(12, 5))  \n",
    "\n",
    "    # 作圖損失\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, train_loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.title(f'{model_name} Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # 作圖準確率\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, train_accuracy, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_accuracy, label='Validation Accuracy')\n",
    "    plt.title(f'{model_name} Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # 顯示圖片\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{model_name} Loss and Accuracy\")\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def plot_confusion_matrix(y_true, y_pred, labels=None, title='Confusion Matrix'):\n",
    "    \"\"\"\n",
    "    繪製混淆矩陣的函數。\n",
    "    \n",
    "    參數:\n",
    "    y_true: 真實標籤列表或數組。\n",
    "    y_pred: 預測標籤列表或數組。\n",
    "    labels: 標籤的名稱列表，用於標記矩陣的軸。\n",
    "    title: 圖表的標題。\n",
    "    \"\"\"\n",
    "    # 計算混淆矩陣\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    # 創建一個熱圖，顯示混淆矩陣\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title(title)\n",
    "    plt.savefig(f\"Inference confusion metrix\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm_normalized, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    \n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title(f'{title} normalized')\n",
    "    plt.savefig(f\"Inference confusion metrix normalized\")\n",
    "    plt.show()\n",
    "    \n",
    "def plot_misclassified_with_probabilities(test_dataset, model_name ,y_true, y_pred, y_probs, class_names, num_images_to_plot=5):\n",
    "    \"\"\"\n",
    "    畫出預測錯誤的圖片。\n",
    "    \n",
    "    參數:\n",
    "    - test_dataset: 用於測試的tf.data.Dataset物件。\n",
    "    - y_true: 真實標籤的數組或列表。\n",
    "    - y_pred: 預測標籤的數組或列表。\n",
    "    - class_names: 分類標籤名稱的列表。\n",
    "    - num_images_to_plot: 要顯示的錯誤圖片的數量。\n",
    "    \"\"\"\n",
    "    # 找出預測錯誤的 index\n",
    "      # 找出預測錯誤的 index\n",
    "    incorrect_indices = np.where(np.array(y_true) != np.array(y_pred))[0]\n",
    "\n",
    "    if len(incorrect_indices) == 0:\n",
    "        print(\"所有圖片均正確分類！\")\n",
    "        return\n",
    "    \n",
    "    num_plots = min(num_images_to_plot, len(incorrect_indices))\n",
    "    print(f\"最少繪製'{num_plots}'張圖片\")\n",
    "    # 計算行列數目\n",
    "    cols = 5\n",
    "    rows = (num_plots + cols - 1) // cols  # 向上取整\n",
    "\n",
    "    plt.figure(figsize=(15, 5 * rows))\n",
    "\n",
    "    count = 0\n",
    "    global_index = 0\n",
    "    for images, _ in test_dataset:\n",
    "        for i in range(len(images)): #batch?32\n",
    "            if count >= num_plots:\n",
    "                break\n",
    "            if global_index in incorrect_indices:\n",
    "                # 獲取該圖片真實標籤與預測信息\n",
    "                true_label_index = class_names.get(y_true[global_index]) #0123\n",
    "                predicted_label_index = class_names.get(y_pred[global_index]) #0123\n",
    "                true_label_prob = y_probs[global_index][true_label_index]\n",
    "                predicted_label_prob = y_probs[global_index][predicted_label_index]\n",
    "                \n",
    "                ax = plt.subplot(rows, cols, count + 1)\n",
    "                plt.imshow(images[i].numpy().astype(\"int32\"))  # 確保圖片是可視化格式\n",
    "                plt.title(f\"True: {y_true[global_index]} ({true_label_prob:.2f})\\n\"\n",
    "                          f\"Pred: {y_pred[global_index]} ({predicted_label_prob:.2f})\")\n",
    "                plt.axis(\"off\")\n",
    "                count += 1\n",
    "            global_index += 1\n",
    "\n",
    "        if count >= num_plots:\n",
    "            break\n",
    "    plt.title(f\"{model_name} wrong predicted images\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{model_name} wrong predicted images\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f964fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Fold 1 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 09:01:51.922933: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-21 09:01:51.922976: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-21 09:01:51.922986: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-21 09:01:52.642637: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-21 09:01:52.642666: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-21 09:01:52.642671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-04-21 09:01:52.642692: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-21 09:01:52.642718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21208 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 09:02:16.872925: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 90500\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1745226137.175329  366993 service.cc:145] XLA service 0x7f9a52f381b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1745226137.175356  366993 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "I0000 00:00:1745226137.284335  366993 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/93 [..............................] - ETA: 35:31 - loss: 0.5557 - accuracy: 0.9375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 09:02:19.028942: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - ETA: 0s - loss: 1.9526 - accuracy: 0.5332"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 55s 347ms/step - loss: 1.9526 - accuracy: 0.5332 - val_loss: 2.0753 - val_accuracy: 0.4316 - lr: 5.0000e-04\n",
      "Epoch 2/500\n",
      "93/93 [==============================] - 24s 256ms/step - loss: 1.4430 - accuracy: 0.5285 - val_loss: 0.7605 - val_accuracy: 0.6694 - lr: 5.0000e-04\n",
      "Epoch 3/500\n",
      "93/93 [==============================] - 24s 255ms/step - loss: 0.8849 - accuracy: 0.6491 - val_loss: 0.5052 - val_accuracy: 0.8144 - lr: 5.0000e-04\n",
      "Epoch 4/500\n",
      "93/93 [==============================] - 24s 258ms/step - loss: 0.6161 - accuracy: 0.7703 - val_loss: 0.4394 - val_accuracy: 0.8388 - lr: 5.0000e-04\n",
      "Epoch 5/500\n",
      "93/93 [==============================] - 24s 257ms/step - loss: 0.5456 - accuracy: 0.8008 - val_loss: 0.3968 - val_accuracy: 0.8503 - lr: 5.0000e-04\n",
      "Epoch 6/500\n",
      "93/93 [==============================] - 24s 259ms/step - loss: 0.4763 - accuracy: 0.8381 - val_loss: 0.3614 - val_accuracy: 0.8652 - lr: 5.0000e-04\n",
      "Epoch 7/500\n",
      "93/93 [==============================] - 23s 253ms/step - loss: 0.4053 - accuracy: 0.8577 - val_loss: 0.3878 - val_accuracy: 0.8489 - lr: 5.0000e-04\n",
      "Epoch 8/500\n",
      "93/93 [==============================] - 23s 253ms/step - loss: 0.3765 - accuracy: 0.8753 - val_loss: 0.3188 - val_accuracy: 0.8767 - lr: 5.0000e-04\n",
      "Epoch 9/500\n",
      "93/93 [==============================] - 23s 253ms/step - loss: 0.3223 - accuracy: 0.8950 - val_loss: 0.3126 - val_accuracy: 0.8808 - lr: 5.0000e-04\n",
      "Epoch 10/500\n",
      "93/93 [==============================] - 24s 254ms/step - loss: 0.2986 - accuracy: 0.9045 - val_loss: 0.2938 - val_accuracy: 0.8855 - lr: 5.0000e-04\n",
      "Epoch 11/500\n",
      "93/93 [==============================] - 24s 255ms/step - loss: 0.2715 - accuracy: 0.9153 - val_loss: 0.2770 - val_accuracy: 0.8977 - lr: 5.0000e-04\n",
      "Epoch 12/500\n",
      "93/93 [==============================] - 24s 257ms/step - loss: 0.2382 - accuracy: 0.9275 - val_loss: 0.2767 - val_accuracy: 0.9018 - lr: 5.0000e-04\n",
      "Epoch 13/500\n",
      "93/93 [==============================] - 24s 256ms/step - loss: 0.2218 - accuracy: 0.9363 - val_loss: 0.2668 - val_accuracy: 0.9038 - lr: 5.0000e-04\n",
      "Epoch 14/500\n",
      "93/93 [==============================] - 24s 259ms/step - loss: 0.1913 - accuracy: 0.9472 - val_loss: 0.2575 - val_accuracy: 0.9085 - lr: 5.0000e-04\n",
      "Epoch 15/500\n",
      "93/93 [==============================] - 24s 256ms/step - loss: 0.1805 - accuracy: 0.9458 - val_loss: 0.2651 - val_accuracy: 0.9051 - lr: 5.0000e-04\n",
      "Epoch 16/500\n",
      "93/93 [==============================] - 24s 263ms/step - loss: 0.1729 - accuracy: 0.9533 - val_loss: 0.2555 - val_accuracy: 0.9119 - lr: 5.0000e-04\n",
      "Epoch 17/500\n",
      "93/93 [==============================] - 24s 256ms/step - loss: 0.1519 - accuracy: 0.9600 - val_loss: 0.2474 - val_accuracy: 0.9133 - lr: 5.0000e-04\n",
      "Epoch 18/500\n",
      "93/93 [==============================] - 24s 257ms/step - loss: 0.1375 - accuracy: 0.9621 - val_loss: 0.2427 - val_accuracy: 0.9146 - lr: 5.0000e-04\n",
      "Epoch 19/500\n",
      "93/93 [==============================] - 23s 253ms/step - loss: 0.1170 - accuracy: 0.9715 - val_loss: 0.2588 - val_accuracy: 0.9112 - lr: 5.0000e-04\n",
      "Epoch 20/500\n",
      "93/93 [==============================] - 23s 253ms/step - loss: 0.1160 - accuracy: 0.9695 - val_loss: 0.2615 - val_accuracy: 0.9106 - lr: 5.0000e-04\n",
      "Epoch 21/500\n",
      "93/93 [==============================] - 24s 256ms/step - loss: 0.1068 - accuracy: 0.9749 - val_loss: 0.2478 - val_accuracy: 0.9126 - lr: 5.0000e-04\n",
      "Epoch 22/500\n",
      "93/93 [==============================] - 24s 258ms/step - loss: 0.0997 - accuracy: 0.9709 - val_loss: 0.2369 - val_accuracy: 0.9173 - lr: 5.0000e-04\n",
      "Epoch 23/500\n",
      "93/93 [==============================] - 24s 256ms/step - loss: 0.0826 - accuracy: 0.9797 - val_loss: 0.2600 - val_accuracy: 0.9126 - lr: 5.0000e-04\n",
      "Epoch 24/500\n",
      "93/93 [==============================] - 24s 255ms/step - loss: 0.0884 - accuracy: 0.9783 - val_loss: 0.2443 - val_accuracy: 0.9167 - lr: 5.0000e-04\n",
      "Epoch 25/500\n",
      "93/93 [==============================] - 24s 257ms/step - loss: 0.0785 - accuracy: 0.9810 - val_loss: 0.2388 - val_accuracy: 0.9187 - lr: 5.0000e-04\n",
      "Epoch 26/500\n",
      "93/93 [==============================] - 24s 255ms/step - loss: 0.0756 - accuracy: 0.9817 - val_loss: 0.2396 - val_accuracy: 0.9207 - lr: 5.0000e-04\n",
      "Epoch 27/500\n",
      "93/93 [==============================] - 24s 259ms/step - loss: 0.0574 - accuracy: 0.9892 - val_loss: 0.2332 - val_accuracy: 0.9255 - lr: 5.0000e-04\n",
      "Epoch 28/500\n",
      "93/93 [==============================] - 23s 254ms/step - loss: 0.0628 - accuracy: 0.9844 - val_loss: 0.2489 - val_accuracy: 0.9214 - lr: 5.0000e-04\n",
      "Epoch 29/500\n",
      "93/93 [==============================] - 24s 259ms/step - loss: 0.0592 - accuracy: 0.9831 - val_loss: 0.2364 - val_accuracy: 0.9289 - lr: 5.0000e-04\n",
      "Epoch 30/500\n",
      "93/93 [==============================] - 24s 255ms/step - loss: 0.0541 - accuracy: 0.9851 - val_loss: 0.2393 - val_accuracy: 0.9248 - lr: 5.0000e-04\n",
      "Epoch 31/500\n",
      "93/93 [==============================] - 23s 251ms/step - loss: 0.0456 - accuracy: 0.9858 - val_loss: 0.2417 - val_accuracy: 0.9255 - lr: 5.0000e-04\n",
      "Epoch 32/500\n",
      "93/93 [==============================] - 23s 254ms/step - loss: 0.0413 - accuracy: 0.9912 - val_loss: 0.2452 - val_accuracy: 0.9228 - lr: 5.0000e-04\n",
      "Epoch 33/500\n",
      "93/93 [==============================] - 23s 253ms/step - loss: 0.0411 - accuracy: 0.9898 - val_loss: 0.2391 - val_accuracy: 0.9255 - lr: 5.0000e-04\n",
      "Epoch 34/500\n",
      "93/93 [==============================] - 24s 255ms/step - loss: 0.0367 - accuracy: 0.9912 - val_loss: 0.2522 - val_accuracy: 0.9207 - lr: 5.0000e-04\n",
      "Epoch 35/500\n",
      "93/93 [==============================] - 24s 264ms/step - loss: 0.0303 - accuracy: 0.9939 - val_loss: 0.2745 - val_accuracy: 0.9201 - lr: 5.0000e-04\n",
      "Epoch 36/500\n",
      "93/93 [==============================] - 23s 252ms/step - loss: 0.0345 - accuracy: 0.9939 - val_loss: 0.2556 - val_accuracy: 0.9221 - lr: 5.0000e-04\n",
      "Epoch 37/500\n",
      "93/93 [==============================] - 23s 249ms/step - loss: 0.0277 - accuracy: 0.9939 - val_loss: 0.2451 - val_accuracy: 0.9289 - lr: 5.0000e-04\n",
      "Epoch 38/500\n",
      "93/93 [==============================] - 24s 257ms/step - loss: 0.0248 - accuracy: 0.9953 - val_loss: 0.2324 - val_accuracy: 0.9295 - lr: 2.5000e-04\n",
      "Epoch 39/500\n",
      "93/93 [==============================] - 23s 253ms/step - loss: 0.0176 - accuracy: 0.9966 - val_loss: 0.2362 - val_accuracy: 0.9282 - lr: 2.5000e-04\n",
      "Epoch 40/500\n",
      "93/93 [==============================] - 24s 257ms/step - loss: 0.0149 - accuracy: 0.9973 - val_loss: 0.2352 - val_accuracy: 0.9316 - lr: 2.5000e-04\n",
      "Epoch 41/500\n",
      "93/93 [==============================] - 24s 257ms/step - loss: 0.0143 - accuracy: 0.9973 - val_loss: 0.2377 - val_accuracy: 0.9302 - lr: 2.5000e-04\n",
      "Epoch 42/500\n",
      "93/93 [==============================] - 24s 256ms/step - loss: 0.0122 - accuracy: 0.9980 - val_loss: 0.2357 - val_accuracy: 0.9329 - lr: 2.5000e-04\n",
      "Epoch 43/500\n",
      "93/93 [==============================] - 23s 253ms/step - loss: 0.0140 - accuracy: 0.9986 - val_loss: 0.2347 - val_accuracy: 0.9302 - lr: 2.5000e-04\n",
      "Epoch 44/500\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.9993"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(file_paths)):\n",
    "    print(f\"\\n========== Fold {fold + 1} ==========\")\n",
    "\n",
    "    train_paths, val_paths = file_paths[train_idx], file_paths[val_idx]\n",
    "    train_labels, val_labels = labels[train_idx], labels[val_idx]\n",
    "\n",
    "    # 建立 Dataset\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\n",
    "    val_ds = tf.data.Dataset.from_tensor_slices((val_paths, val_labels))\n",
    "\n",
    "    # 讀圖片\n",
    "    def load_and_preprocess_image(path, label):\n",
    "        image = tf.io.read_file(path)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH])\n",
    "        return image, label\n",
    "\n",
    "    train_ds = train_ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE).map(augment).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    val_ds = val_ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE).map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    # 建立 model & callbacks\n",
    "    model = create_model(ConvNeXtSmall)\n",
    "\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6),\n",
    "        tf.keras.callbacks.ModelCheckpoint(f'ConvNeXtSmall_best_model_fold{fold + 1}.h5', monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "    ]\n",
    "\n",
    "    history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, callbacks=callbacks)\n",
    "    plot_training_history(history,\"ConvNeXtSmall\")\n",
    "    test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    TEST_DIR,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    shuffle=False\n",
    "    )\n",
    "    test_dataset = test_dataset.map(preprocess)\n",
    "    true_labels = []\n",
    "    for _, label in test_dataset:\n",
    "        batch_labels = label.numpy()\n",
    "        class_indices = np.argmax(batch_labels, axis=1)\n",
    "        true_labels.extend(class_indices)\n",
    "\n",
    "    # 最後一個 fold 測試\n",
    "    loss, acc = model.evaluate(test_dataset)\n",
    "    print(f\"Inference Test Accuracy (Last Fold): {acc:.4f}\")\n",
    "    with open(\"test_inference.txt\",\"+a\",encoding=\"utf-8\") as file:\n",
    "        file.write(f\"Fold {fold+1} Inference metric loss:{loss}, acc:{acc}\\n\")\n",
    "    evaluate_result = model.evaluate(test_dataset)\n",
    "    predict_result = model.predict(test_dataset)\n",
    "    predict_classes = np.argmax(predict_result,axis=1)\n",
    "    reverse_name = {k:v for k,v in enumerate(class_names)}\n",
    "    y_true = [reverse_name.get(i) for i in true_labels]\n",
    "    y_pred = [reverse_name.get(i) for i in predict_classes]\n",
    "    name_to_int = {v:k for k,v in enumerate(class_names)}\n",
    "    plot_confusion_matrix(y_true=y_true,y_pred=y_pred,labels=class_names)\n",
    "    plot_misclassified_with_probabilities(test_dataset, model_name=\"ConvNeXtSmall\", y_true=y_true, y_pred=y_pred, y_probs=predict_result, class_names=name_to_int, num_images_to_plot=100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
